[{"content":"","date":"14 September 2024","externalUrl":null,"permalink":"/tags/canal/","section":"Tags","summary":"","title":"Canal","type":"tags"},{"content":" 测试背景 # 本次测试在本地,用3个库做同步测试,由canal_master_1和canal_master_2往canal_sync同步数据 文件配置 # canal的配置会涉及到文件夹、配置文件、配置文件之间的关联,总的逻辑关系如下 deployer配置 # deployer的主要作用是对数据库进行监听,伪装destination的从库，解析其binlog\ncanal/conf/canal.properties 是deployer主配置我们主要关注destinations下的配置\n################################################# ######### destinations\t############# ################################################# # master1和master2对应着conf下的两个文件夹，其中存放着具体的监听库信息、库表过滤规则等 canal.destinations = master1,master2 ps:多余配置已经裁剪,只关注主要修改配置\nmaster1(2)文件夹配置 # master1(2)文件夹就对应着destinations中的配置项，其含义是被监听的数据源，该文件夹下存放其相关配置在instance.properties\n# username/password canal.instance.master.address=127.0.0.1:3306 canal.instance.dbUsername=root canal.instance.dbPassword=12345678 canal.instance.connectionCharset = UTF-8 # 默认监听源数据库 canal.instance.defaultDatabaseName=canal_master_1 canal.instance.enableDruid=false # table regex canal.instance.filter.regex=canal_master_1.order,canal_master_1.order_item adapter配置 # adapter端的作用是解析来自deployer端的binlog数据并适配转储到各种数据库本次案例中是从mysql适配到mysql.\nadapter的主配置在conf/application.yml\nouterAdapters代表着外部适配器配置，也就是conf配置下单独拎出来文件夹存放配置的意思\nname 代表文件夹名称，这里mysql使用的是rdb key 是代表具体配置名称，该配置主要是配置映射规则 properties 其下配置的是需要同步到的数据库，及目标库这里目标库只有一个canal_sync所以保持一致即可 server: port: 8081 spring: jackson: date-format: yyyy-MM-dd HH:mm:ss time-zone: GMT+8 default-property-inclusion: non_null canal.conf: mode: tcp #tcp kafka rocketMQ rabbitMQ flatMessage: true zookeeperHosts: syncBatchSize: 1000 retries: -1 timeout: accessKey: secretKey: consumerProperties: # canal tcp consumer canal.tcp.server.host: 127.0.0.1:11111 canal.tcp.batch.size: 500 srcDataSources: defaultDS: url: jdbc:mysql://127.0.0.1:3306/canal_master_1 username: root password: 12345678 canalAdapters: - instance: master1 # canal instance Name or mq topic name groups: - groupId: g1 outerAdapters: - name: rdb key: master1Mapping properties: jdbc.driverClassName: com.mysql.jdbc.Driver jdbc.url: jdbc:mysql://127.0.0.1:3306/canal_sync jdbc.username: root jdbc.password: 12345678 druid.stat.enable: false druid.stat.slowSqlMillis: 1000 - instance: master2 # canal instance Name or mq topic name groups: - groupId: g1 outerAdapters: - name: rdb key: master2Mapping properties: jdbc.driverClassName: com.mysql.jdbc.Driver jdbc.url: jdbc:mysql://127.0.0.1:3306/canal_sync jdbc.username: root jdbc.password: 12345678 druid.stat.enable: false druid.stat.slowSqlMillis: 1000 outerAdapters # 配置master1Mapping.yml时可以用dataSourceKey 关联数据源，也可以使用destination来关联数据源\n#dataSourceKey: defaultDS destination: master1 groupId: g1 outerAdapterKey: master1Mapping concurrent: true dbMapping: database: canal_master_1 table: order targetTable: order targetPk: id: id tenant_id: tenant_id mapAll: true commitBatch: 3000 # 批量提交的大小 至此配置已经完成，接下来我将针对给出的配置给到具体的测试数据\n测试报告 # 双库插入,同步库同步情况 # 测试案例: master1 和 master2 各自写入一条数据观察 canal_sync库数据情况 测试结果: 我们可以通过日志观测到数据已经被adapter解析并执行同步 插入结果 验证destination 和 dataSourceKey # 测试案例: 注释掉master1Mapping 和 master2Mapping 中的destination，启动后做数据同步\n测试结果: 数据同步均失败\n原因分析: 默认情况下adapter会从deployer中拉取binlog，并转换成目标格式。但是在某些情况下可能需要进行回查等操作，就需要用到 dataSourceKey中的配置信息\n至此此次测试案例结束\n参考链接: srcDataSources的作用是什么\n","date":"14 September 2024","externalUrl":null,"permalink":"/devops/2.canal%E5%A4%9A%E5%AF%B9%E4%B8%80%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E6%B5%8B%E8%AF%95%E6%A1%88%E4%BE%8B/","section":"Devops","summary":"","title":"Canal多对一数据同步测试案例","type":"devops"},{"content":"","date":"14 September 2024","externalUrl":null,"permalink":"/series/canal%E8%B0%83%E7%A0%94%E5%BA%94%E7%94%A8/","section":"Series","summary":"","title":"Canal调研应用","type":"series"},{"content":"","date":"14 September 2024","externalUrl":null,"permalink":"/devops/","section":"Devops","summary":"","title":"Devops","type":"devops"},{"content":"","date":"14 September 2024","externalUrl":null,"permalink":"/tags/%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/","section":"Tags","summary":"","title":"数据同步","type":"tags"},{"content":"","date":"14 September 2024","externalUrl":null,"permalink":"/tags/%E6%B5%8B%E8%AF%95%E6%A1%88%E4%BE%8B/","section":"Tags","summary":"","title":"测试案例","type":"tags"},{"content":"","date":"14 September 2024","externalUrl":null,"permalink":"/categories/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/","section":"Categories","summary":"","title":"编程开发","type":"categories"},{"content":" 业务背景 # 我们有这样的一个场景，一个主系统和N个子系统，子系统之间数据隔离,主系统有全部数据。\n于是针对数据同步就有了两个需求点\n需要可以在将N个子系统的数据实时同步到主系统 需要考虑主子系统之间出现网路隔离子系统仍然正常工作可操作,再网络恢复后主子系统之间进行数据的增量同步。 在这样的背景下我们准备对阿里的cannel和dataX两个工具进行调研\n前置条件 # 目前canal 支持源端 MySQL 版本包括 5.1.x , 5.5.x , 5.6.x , 5.7.x , 8.0.x mysql需要开启binglog # binlog查询命令 show variables like \u0026#39;log_bin\u0026#39;; # mysql开启binlog [mysqld] # 打开binlog log-bin=mysql-bin # 选择ROW(行)模式 binlog-format=ROW # 配置MySQL replaction需要定义，不要和canal的slaveId重复 server_id=1 # 要监控的数据库名称 binlog-do-db=my-test canal原理 # canal的工作原理可以是基于主从同步,但是与主从同步不完全相同。\ncanal是通过伪装成从库通过dump协议从mysql拉取binlog日志，解析binlog日志并将解析后的数据应用到目标数据库\n主从同步通过dump协议拉取binlog日志后，通过binlog回放来达到数据同步的目的\nps:\n主从同步在断网重连的场景下,如果断网时间过长，在数据一致性这块可能会有问题（binlog位置不一致,relay log 损坏，数据冲突等原因）， 需要依赖三方的工具检查和手动解决。\ncanal针对于断网恢复后的数据一致性问题，给出了持久化binlog同步位置信息的方案（文件或者数据库都可），以保证断网后不存在数据一致性问题 业务场景匹配度 # canal支持多子库往一个主库同步的情况 相对于主从同步下的数据一致性问题，canal本身就给了解决方案，无需再借用第三方工具来处理 ","date":"13 September 2024","externalUrl":null,"permalink":"/devops/1.canal%E7%9A%84%E8%B0%83%E7%A0%94/","section":"Devops","summary":"","title":"canal调研","type":"devops"},{"content":"","date":"11 September 2024","externalUrl":null,"permalink":"/structure/","section":"Structures","summary":"","title":"Structures","type":"structure"},{"content":" 栈 # 定义 # 栈是一种特殊的线性表,只可以在线性表的底部进行插入和删除操作.\n线性表的头部被称为栈底,底部被成为栈顶,也就是说栈只可以在栈顶进行插入或者删除操作\n插入操作被称为压栈(push) 删除操作被叫做弹栈(pop). 抽象数据类型 # 数据 # AbstractStack\n行为 # IStack\nIShardedStack.java\n栈的种类 # 数组栈和链表栈 # 因为栈是特殊的线性表，所以很自然的就想到存在数组和链表两种实现方式。 个人觉得数组这种方式特别合适，因为我们限定了所有操作都要在栈顶，而链表方式会多一些额外开销。\n共享栈 # 共享栈就是两个栈分享一个数组/节点链表，栈顶由单个栈的时候的数组最大值，变成了两个栈顶\u0026quot;发生碰撞\u0026quot; 栈的应用 # 递归 # 递归的典型运用场景就是斐波那契数列\n斐波那契数列: 前两项数的和 f(0) = 0; f(1) = 1; f(n) = f(n-1) + f(n-2);\n普通的执行方法如果我们要算f(20),那么要从 f(0) f(1) f(2)一步步计算到f(20);\n使用递归的化我们是从f(20)开始分解公式,f(20) = f(19) + f(18);再去调用f(18) 和 f(19) 依次往下自己调用自己。\n在这个依次向下的调用过程我们就需要 \u0026ldquo;先将上层的公式存起来\u0026rdquo; 先存起来的公式后算,这和栈结构不谋而合，而在java中执行方法的压栈和出栈也确实是这样的。\n四则运算法则 # 我们常见的表达式 9+（3－1）×3+10÷2 叫做中缀表达式，我们可以很轻松的依据优先级 “ 括号 大于 乘除 大于 加减” 来算出结果\n但是计算机在处理中缀表达式的时候就很难办,于是 波兰的一位逻辑学家 想出来了一个后缀(逆波兰)表达式, 而上述中缀表达式转换后未 9 3 1 - 3 * + 10 2 / +\n中缀表达式转后缀表达式 # 中缀表达式提取后缀表达的基本步骤:\n依次读取表达式中的每一项 符号和数字 ，读取到数字则放到后缀表达式中，读取到符号则放入计算符号栈中 如果栈顶 无符号 或者 优先级小于 当前要放入的符号,则直接放入 如果放入的符号 优先级大于当前符号则取出栈中的所有符号加入表达式 再放入符号 如果放入的符号是) 则取出符号直到(为止 加入表达式 然后再放入符号 后缀表达式的计算逻辑 # 依次将每个表达式的元素放入到计算栈中 如果获取到计算符号则从栈中取出两个数进行计算，之后再放入到栈中 最后计算结束取出栈中数据即可 ","date":"11 September 2024","externalUrl":null,"permalink":"/structure/stack/","section":"Structures","summary":"","title":"一文读懂栈","type":"structure"},{"content":" 队列 # 定义 # 队列是一种特殊的线性表,他的特殊性在于将线性表的操作限定为表尾插入，表头删除\n通过这个特殊的限定我们可以达到FIFO(first in first out)的目的\n抽象数据类型 # Queue.java\n队列的数组实现（循环队列） # CircleQueue.java\n队列数据存储的问题 # 虽然我们采用数组来作为数据存储的基本结构，但是由于队列的使用过程中头尾指针是动态的。\n所以我们很容一造成头指针到index = 0 之间的空间浪费 因此我们采用 尾指针 = (尾指针 + 1) % data.length的方式来移动尾指针，让尾指针可以循环起来\n这样就解决了存储空间浪费的问题\n尾指针移动的几个问题， # CircleQueue.java#rearMove\n按照正常情况下，队列临界的问题判断应该如下\n# 队列满 this.font == this.rear # 队列空 this.font == this.rear 我们无法区分队列满 和 队列空，需要引入一个新的变量flag来判断。\n我们这里可以使用空出最后一个存储空间的方式来达到该目的，而不用引入新的状态\nthis.rear = ++this.rear % data.length; if (this.rear == this.front){ throw new RuntimeException(\u0026#34;rear is out of size\u0026#34;); } 队列的链表实现实现 # LinkedQueue.java\n","date":"11 September 2024","externalUrl":null,"permalink":"/structure/queue/","section":"Structures","summary":"","title":"一文读懂队列","type":"structure"},{"content":"","date":"11 September 2024","externalUrl":null,"permalink":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%A0%88/","section":"Tags","summary":"","title":"数据结构-栈","type":"tags"},{"content":"","date":"11 September 2024","externalUrl":null,"permalink":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E9%98%9F%E5%88%97/","section":"Tags","summary":"","title":"数据结构-队列","type":"tags"},{"content":"","date":"11 September 2024","externalUrl":null,"permalink":"/series/%E9%87%8D%E5%AD%A6%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","section":"Series","summary":"","title":"重学数据结构","type":"series"},{"content":"","externalUrl":null,"permalink":"/en/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/en/","section":"BlueWhale🐳","summary":"","title":"BlueWhale🐳","type":"page"},{"content":"","externalUrl":null,"permalink":"/en/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/menu/","section":"Menus","summary":"","title":"Menus","type":"menu"},{"content":"","externalUrl":null,"permalink":"/en/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","externalUrl":null,"permalink":"/en/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":" togally/BlueWhale HTML 1 0 ","externalUrl":null,"permalink":"/menu/project/","section":"Menus","summary":"","title":"项目","type":"menu"}]